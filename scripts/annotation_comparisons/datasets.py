import pandas as pd

from .definitions import (
    low_res_oc_hpa_labels, 
    high_res_oc_hpa_labels, 
    low_res_oc_yeast_labels, 
    high_res_oc_yeast_labels, 
)


def map_to_consensus(map_kind, label_kind, res):
    '''
    Transform a primary label to consensus label
    map_kind : the kind of label mapping (i.e., from OC to either 'hpa' or 'yeast')
    label_kind : the kind of primary label to map ('oc', 'yeast', 'hpa')
    res : the resolution of consensus labels to use for the mapping ('low' or 'high')
    '''
    if map_kind == 'yeast':
        consensus_labels = low_res_oc_yeast_labels if res == 'low' else high_res_oc_yeast_labels
    else:
        consensus_labels = low_res_oc_hpa_labels if res == 'low' else high_res_oc_hpa_labels

    def mapper(label):
        for consensus_label in consensus_labels:
            primary_labels = consensus_label[label_kind]
            if isinstance(primary_labels, str):
                primary_labels = tuple([primary_labels])
            if label in primary_labels:
                return consensus_label['consensus']
        return None
    return mapper


def load_yeast_homologs():
    '''
    Load a list of human-yeast homologous proteins
    (manually generated by Manu in June 2021 using the ensembl UI)

    Notes
    There is a many-to-many mapping between yeast gene IDs and ensg_ids

    There is a one-to-one mapping between the yeast gene IDs and names,
    though some yeast genes do not have names (only ids)
    '''
    df = pd.read_csv('../data/external/human_Ensembl_to_yeast_061021.txt', sep='\t')

    df.rename(
        columns={
            'Gene stable ID': 'ensg_id',
            'Saccharomyces cerevisiae gene stable ID': 'orf_id',
            'Saccharomyces cerevisiae gene name': 'yeast_gene_name'
        },
        inplace=True
    )

    # we only need the gene IDs
    df = df[['ensg_id', 'orf_id']]

    # drop genes without homologs
    df.dropna(how='any', axis=0, subset=['ensg_id', 'orf_id'], inplace=True)

    # eliminate duplicates (presumably due to transcript-level distinctions)
    df = df.groupby(['ensg_id', 'orf_id']).first().reset_index()
    return df


def load_yeast_annotations(res, append_human_homologs=True, include_only_1to1_homologs=False):
    '''
    Load protein localization annotations from the Loqate project
    https://www.weizmann.ac.il/molgen/loqate/downloads

    This uses a manually-downloaded spreadsheet of annotations (manually converted to CSV)
    The 'ORF' and 'Gene' columns are unique
    The '* Localization' columns contain a colon-separated list of localization labels
    '''
    yeast_ants = pd.read_csv('../data/external/yeast_localization_annotations.csv')
    yeast_ants.rename(
        columns={
            'ORF': 'orf_id',
            'Gene': 'gene_name',
            'Description': 'description',
            'control Localization': 'original_label'
        },
        inplace=True
    )
    yeast_ants = yeast_ants[['orf_id', 'gene_name', 'description', 'original_label']]

    # parse the labels
    yeast_ants['original_label'] = yeast_ants.original_label.str.split(':')
    yeast_ants = yeast_ants.explode('original_label')

    # create consensus labels
    yeast_ants['consensus_label'] = yeast_ants['original_label'].apply(
        map_to_consensus(map_kind='yeast', label_kind='yeast', res=res)
    )

    # drop labels without a consensus label 
    # (this drops the 'below threshold' and 'ambiguous' labels)
    yeast_ants = yeast_ants.dropna(axis=0, how='any', subset=['consensus_label'])

    # drop duplicate consensus labels
    yeast_ants = yeast_ants.groupby(['gene_name', 'consensus_label']).first().reset_index()

    if not append_human_homologs:
        return yeast_ants

    # load the list of human-yeast homologs
    homologs = load_yeast_homologs()

    # optionally only retain one-to-one homolog pairs
    if include_only_1to1_homologs:
        n_ensg = homologs.ensg_id.value_counts()
        n_orf = homologs.orf_id.value_counts()                         
        homologs = homologs.loc[
            homologs.ensg_id.isin(n_ensg[n_ensg == 1].index) & 
            homologs.orf_id.isin(n_orf[n_orf == 1].index)
        ]
    
    yeast_ants = pd.merge(yeast_ants, homologs, left_on='orf_id', right_on='orf_id', how='inner')

    # here we drop the ensg_ids whose orfs do not all share the same label sets
    counts = (
        # concat the labels for each homolog pair
        yeast_ants.groupby(['orf_id', 'ensg_id'])
        .consensus_label.agg(lambda d: tuple(set(d)))
        .reset_index()

        # count the number of distinct label sets for each ensg_id 
        # (this will be greater than one only for ensg_ids with multiple homologs
        # whose label sets are not the same)
        .groupby('ensg_id').nunique()
    )
    yeast_ants = yeast_ants.loc[yeast_ants.ensg_id.isin(counts[counts.consensus_label == 1].index)]

    # now we can safely eliminate duplicated ensg_ids 
    # (since we only need the consensus label sets for each ensg_id, not the actual homologs)
    yeast_ants = yeast_ants.groupby('ensg_id').first().reset_index()

    return yeast_ants


def load_oc_annotations(map_kind, res='high'):
    '''
    Load the OpenCell annotations from either the preprint supp table of annotations 
    (which have some omissions) or the final, clean annotations

    map_kind : the kind of mapping to use to generate the consensus labels
        (either 'hpa' or 'yeast')
    res : 'high' or 'low' (for 'hpa' mapping only)
    '''
    oc_ants = pd.read_csv('../data/2021-09-29-public-annotations-flat.csv')

    # targets wo graded annotations
    targets_without_grade23 = (
        set(oc_ants.target_name) - set(oc_ants.loc[oc_ants.annotation_grade.isin(['2', '3'])].target_name)
    )
    if targets_without_grade23:
        print('These targets have no grade-2 or -3 annotations: %s' % targets_without_grade23)

    # drop these non-graded annotations and the grade-1 annotations
    oc_ants = oc_ants.loc[oc_ants.annotation_grade.isin(['2', '3'])]

    # create consensus labels
    oc_ants['consensus_label'] = oc_ants.annotation_name.apply(
        map_to_consensus(map_kind=map_kind, label_kind='oc', res=res)
    )
    # drop labels without a consensus label
    target_names = set(oc_ants.target_name)
    oc_ants = oc_ants.dropna(axis=0, how='any', subset=['consensus_label'])

    targets_wo_consensus = target_names.difference(oc_ants.target_name)
    if targets_wo_consensus:
        print('These targets have no consensus labels: %s' % targets_wo_consensus)

    # drop duplicate consensus labels
    oc_ants = oc_ants.groupby(['ensg_id', 'consensus_label']).first().reset_index()

    return oc_ants


def load_hpa_annotations(res='high', exclude_uncertain=True):
    '''
    Load HPA annotations from a CSV manually downloaded from the HPA website

    exclude_uncertain : whether to exclude targets whose label reliability is 'uncertain'
    ('uncertain' means that 'the antibody-staining pattern contradicts experimental data 
    or expression is not detected at RNA level.')
    '''
    hpa = pd.read_csv('../data/external/hpa_subcellular_location.tsv', sep='\t')

    hpa.rename(
        columns={column: column.lower().replace(' ', '_') for column in hpa.columns},
        inplace=True
    )

    # the labels are in the 'main_location' column
    hpa.rename(columns={'gene': 'ensg_id', 'main_location': 'hpa_label',}, inplace=True)

    if exclude_uncertain:
        hpa = hpa.loc[hpa.reliability != 'Uncertain']
    
    hpa['hpa_label'] = hpa['hpa_label'].str.split(';')
    hpa = hpa.explode('hpa_label')

    # create consensus labels
    hpa['consensus_label'] = hpa['hpa_label'].apply(
        map_to_consensus(map_kind='hpa', label_kind='hpa', res=res)
    )

    # drop labels without a consensus label
    hpa = hpa.dropna(axis=0, how='any', subset=['consensus_label'])

    # drop duplicate consensus labels
    hpa = hpa.groupby(['ensg_id', 'consensus_label']).first().reset_index()

    return hpa


def merge_targets(
    oc_ants, reference_ants, reference_kind, exclude_multilocalizing=False, how='inner'
):
    '''
    Merge the annotations for all targets and calculate exact and partial match flags
    reference_ants : dataframe with ensg_id and consensus_label columns
    reference_kind : either 'hpa' or 'yeast'
    exclude_multilocalizing : if true, only include targets 
        with only one reference and only one OC annotation
    '''

    consensus_label_reference = 'consensus_label_%s' % reference_kind

    if exclude_multilocalizing:
        label_counts = reference_ants.ensg_id.value_counts()
        reference_ants = reference_ants.loc[
            reference_ants.ensg_id.isin(label_counts.loc[label_counts == 1].index)
        ].copy()

        label_counts = oc_ants.ensg_id.value_counts()
        oc_ants = oc_ants.loc[
            oc_ants.ensg_id.isin(label_counts.loc[label_counts == 1].index)
        ].copy()

    merged = (
        pd.merge(
            oc_ants.groupby('ensg_id').consensus_label.agg(lambda d: tuple(set(d))).reset_index(),
            reference_ants.groupby('ensg_id').consensus_label.agg(lambda d: tuple(set(d))).reset_index(),
            on='ensg_id',
            how=how
        )
        .rename(
            columns={
                'consensus_label_x': 'consensus_label_oc',
                'consensus_label_y': consensus_label_reference
            }
        )
    )

    for ind, row in merged.iterrows():
        if pd.isna(row[consensus_label_reference]):
            continue
        merged.at[ind, 'exact_match'] = (
            set(row.consensus_label_oc) == set(row[consensus_label_reference])
        )
        merged.at[ind, 'partial_match'] = (
            len(set(row.consensus_label_oc).intersection(row[consensus_label_reference])) > 0
        )
    
    # merge the target names from oc_ants
    ensg_names = oc_ants[['ensg_id', 'target_name']].groupby('ensg_id').first().reset_index()
    merged = pd.merge(merged, ensg_names, on='ensg_id', how='inner')
    return merged


def export_consensus_annotations(output_dir, timestamp, reference_kind=None):
    '''
    Export two CSVs: 
    1) the OC and reference consensus annotations for all OpenCell targets
    2) counts of exact and partial matches for all unique sets of consensus annotations

    reference_kind : the reference dataset to use ('hpa' or 'yeast')
    '''

    sep = ', '
    subset = 'all'
    res = 'high'

    # the name of the column of original reference annotations
    original_label_reference = 'original_annotation_%s' % reference_kind

    # the name of the column with consensus reference labels, added by merge_targets
    consensus_label_reference = 'consensus_label_%s' % reference_kind

    oc_ants = load_oc_annotations(map_kind=reference_kind, res=res)

    if reference_kind == 'hpa':
        reference_ants = load_hpa_annotations(res=res, exclude_uncertain=False)

        raw_ref = pd.read_csv('../data/external/hpa_subcellular_location.tsv', sep='\t')
        raw_ref.rename(
            columns={column: column.lower().replace(' ', '_') for column in raw_ref.columns},
            inplace=True
        )
        raw_ref.rename(columns={'gene': 'ensg_id', 'main_location': original_label_reference}, inplace=True)
        raw_ref[original_label_reference] = raw_ref[original_label_reference].apply(lambda s: s.replace(';', sep))

    if reference_kind == 'yeast':
        reference_ants = load_yeast_annotations(res=res)
        raw_ref = reference_ants[['ensg_id', 'original_label']].copy()
        raw_ref.rename(columns={'original_label': original_label_reference}, inplace=True)
        
    # merge left, not inner, to preserve OC targets without HPA annotations
    df = merge_targets(
        oc_ants, 
        reference_ants=reference_ants, 
        reference_kind=reference_kind, 
        exclude_multilocalizing=False, 
        how='left'
    )

    # merge the original reference and OC annotations
    df = df.merge(
        raw_ref.groupby('ensg_id').first().reset_index()[['ensg_id', original_label_reference]],
        on='ensg_id',
        how='left',
    )
    df = df.merge(
        (
            oc_ants.groupby('ensg_id').annotation_name.agg(lambda s: sep.join(s)).reset_index()
            [['ensg_id', 'annotation_name']]
        ),
        on='ensg_id',
        how='left',
    )

    # exclude exact_matches from partial_matches
    df['exact_match'] = df.exact_match.astype(bool)
    df['partial_match'] = (df.partial_match & ~df.exact_match).astype(bool)

    df.at[df[consensus_label_reference].isna(), 'exact_match'] = pd.NA
    df.at[df[consensus_label_reference].isna(), 'partial_match'] = pd.NA

    df['consensus_label_oc'] = df.consensus_label_oc.apply(lambda s: sep.join(s))
    df[consensus_label_reference] = df[consensus_label_reference].apply(
        lambda s: sep.join(s) if not pd.isna(s) else ''
    )

    df.rename(
        columns={
            'annotation_name': 'opencell_annotation',
            'consensus_label_oc': 'consensus_annotation_opencell',
        },
        inplace=True
    )

    columns = [
        'ensg_id', 
        'target_name', 
        'opencell_annotation',
        'consensus_annotation_opencell',
        consensus_label_reference,
        original_label_reference, 
        'exact_match', 
        'partial_match'
    ]

    # export the labels themselves
    (
        df[columns]
        .sort_values(by=['target_name'])
        .to_csv(
            output_dir / (
                f'{timestamp}-oc-{reference_kind}--consensus-labels--{subset}--{res}-res.csv'
            ),
            index=False
        )
    )

    # export the counts for each set of labels
    df = df.loc[df[consensus_label_reference] != ''].copy()

    # coerce to boolean
    df['exact_match'] = df.exact_match.astype(bool)
    df['partial_match'] = df.partial_match.astype(bool)

    counts = df.groupby('consensus_annotation_opencell').sum()[['exact_match', 'partial_match']]
    counts['total'] = df.consensus_annotation_opencell.value_counts()
    counts = counts.sort_values(by='total', ascending=False)

    counts.to_csv(
        output_dir / (f'{timestamp}-oc-{reference_kind}--summary-stats--{subset}--{res}-res.csv')
    )